{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 基本语法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量，类似于np.array\n",
    "x = torch.Tensor(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 未初始化\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 关于operation（以add为例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 3, 4)\n",
    "b = torch.rand(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一种表达：`torch.add`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _和x都是返回值\n",
    "_ = torch.add(a, b, out=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7529, 1.5202, 1.2007, 0.9555],\n",
       "         [0.9421, 0.9205, 0.9212, 1.4600],\n",
       "         [0.2614, 1.4642, 0.5818, 0.8120]],\n",
       "\n",
       "        [[0.4887, 0.9075, 1.7547, 1.0557],\n",
       "         [0.2859, 0.8574, 1.1486, 1.1477],\n",
       "         [1.7011, 1.0521, 1.4676, 0.6632]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7529, 1.5202, 1.2007, 0.9555],\n",
       "         [0.9421, 0.9205, 0.9212, 1.4600],\n",
       "         [0.2614, 1.4642, 0.5818, 0.8120]],\n",
       "\n",
       "        [[0.4887, 0.9075, 1.7547, 1.0557],\n",
       "         [0.2859, 0.8574, 1.1486, 1.1477],\n",
       "         [1.7011, 1.0521, 1.4676, 0.6632]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二种：`a.add(b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7529, 1.5202, 1.2007, 0.9555],\n",
       "         [0.9421, 0.9205, 0.9212, 1.4600],\n",
       "         [0.2614, 1.4642, 0.5818, 0.8120]],\n",
       "\n",
       "        [[0.4887, 0.9075, 1.7547, 1.0557],\n",
       "         [0.2859, 0.8574, 1.1486, 1.1477],\n",
       "         [1.7011, 1.0521, 1.4676, 0.6632]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5296, 0.9916, 0.8949, 0.1198],\n",
       "         [0.1439, 0.8156, 0.2622, 0.6721],\n",
       "         [0.2001, 0.9352, 0.0633, 0.1639]],\n",
       "\n",
       "        [[0.3814, 0.5918, 0.8751, 0.4203],\n",
       "         [0.1515, 0.1049, 0.2912, 0.6927],\n",
       "         [0.7656, 0.2812, 0.7809, 0.0597]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三种：`a.add_(b)`，所有带 _ 的operation，都会更改调用对象的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7529, 1.5202, 1.2007, 0.9555],\n",
       "         [0.9421, 0.9205, 0.9212, 1.4600],\n",
       "         [0.2614, 1.4642, 0.5818, 0.8120]],\n",
       "\n",
       "        [[0.4887, 0.9075, 1.7547, 1.0557],\n",
       "         [0.2859, 0.8574, 1.1486, 1.1477],\n",
       "         [1.7011, 1.0521, 1.4676, 0.6632]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7529, 1.5202, 1.2007, 0.9555],\n",
       "         [0.9421, 0.9205, 0.9212, 1.4600],\n",
       "         [0.2614, 1.4642, 0.5818, 0.8120]],\n",
       "\n",
       "        [[0.4887, 0.9075, 1.7547, 1.0557],\n",
       "         [0.2859, 0.8574, 1.1486, 1.1477],\n",
       "         [1.7011, 1.0521, 1.4676, 0.6632]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 其他运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "abs \n",
      "numpy:  [1 2 1 2] \n",
      "torch:  tensor([1., 2., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)\n",
    "print('\\nabs', '\\nnumpy: ', np.abs(data),'\\ntorch: ', torch.abs(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean \n",
      "numpy:  0.0 \n",
      "torch:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print('\\nmean', '\\nnumpy: ', np.mean(data),'\\ntorch: ', torch.mean(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sin \n",
      "numpy:  [-0.84147098 -0.90929743  0.84147098  0.90929743] \n",
      "torch:  tensor([-0.8415, -0.9093,  0.8415,  0.9093])\n"
     ]
    }
   ],
   "source": [
    "print('\\nsin', '\\nnumpy: ', np.sin(data),'\\ntorch: ', torch.sin(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵乘法需要特别注意！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix \n",
      "numpy:  [[ 7 10]\n",
      " [15 22]] \n",
      "torch:  tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "tensor = torch.FloatTensor(data)\n",
    "# 正确方法\n",
    "print('matrix',\n",
    "     '\\nnumpy: ', np.matmul(data, data),\n",
    "     '\\ntorch: ', torch.mm(tensor, tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-0db0af8c2b61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m print('matrix',\n\u001b[0;32m      4\u001b[0m      \u001b[1;34m'\\nnumpy: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m      '\\ntorch: ', torch.dot(tensor.squeeze(), tensor.squeeze()))\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "# 错误方法, torch.dot只能用于1维的向量\n",
    "data = np.array(data)\n",
    "print('matrix',\n",
    "     '\\nnumpy: ', data.dot(data),\n",
    "     '\\ntorch: ', torch.dot(tensor.squeeze(), tensor.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable # 这里是模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.FloatTensor([[1,2], [3,4]])\n",
    "# requires_grad表示是否参与 BP，要不要计算梯度\n",
    "variable = Variable(tensor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 对比Tensor和Variable的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5000)\n",
      "tensor(7.5000, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "t_out = torch.mean(tensor*tensor)\n",
    "v_out = torch.mean(variable*variable)\n",
    "print(t_out)\n",
    "print(v_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事实上`Variable`在计算的时候在搭建一个计算图，`v_out = torch.mean(variable*variable)`在计算图中添加了一个计算步骤，BP执行的时候它会做出贡献"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(variable.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 获取Variable数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Variable形式\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor形式\n",
    "print(variable.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# numpy形式\n",
    "print(variable.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 关于一些常用函数的说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. `view()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view()`函数的作用是reshape，通常用来将一个多行的Tensor，拼接成一行，比如CNN中在数据进入FC之前，通常有一个Flat操作来，用的就是这个`view()`，`view(m, n)`就会得到一个m*n的Tensor，通常m用1，n用-1表示压成一维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意是顺序填充\n",
    "a.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通常用1和-1来压平\n",
    "a.view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. `squeeze()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`squeeze()`的作用顾名思义，就是挤压，比如如果是一个高维的张量，最高维的维度如果是1，就和比它低1维的张量没什么区别，所以就可以压缩所有为1的维。\n",
    "前面指的是不给`squeeze()`传参的执行，也可以传参，参数为从0开始的整数，表示维度，它会检查相应的维是否维度为1，然后决定是否压缩，其他的位置不受影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[1., 2., 3.]],\n",
      "\n",
      "          [[2., 3., 4.]]]]])\n",
      "torch.Size([1, 1, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[[[[1,2,3]], [[2,3,4]]]]])\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 3., 4.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "b = a.squeeze()\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 2., 3.],\n",
      "          [2., 3., 4.]]]])\n",
      "torch.Size([1, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "b = a.squeeze(3)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. `unsqueeze()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unsqueeze()`的作用和`squeeze()`相反，即拓展维，维度为1，但参数的意思是一样的，不一样的地方在于`unsqueeze()`必须要传参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[1., 2., 3.]],\n",
      "\n",
      "          [[2., 3., 4.]]]]])\n",
      "torch.Size([1, 1, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[[[[1,2,3]], [[2,3,4]]]]])\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[1., 2., 3.]],\n",
      "\n",
      "           [[2., 3., 4.]]]]]])\n",
      "torch.Size([1, 1, 1, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "b = a.unsqueeze(0)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. torch.linspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.linspace(x, y, z)`是一个静态方法，作用是创建一个等分的Tensor，从x到y，维数是z。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0000, -0.8000, -0.6000, -0.4000, -0.2000,  0.0000,  0.2000,  0.4000,\n",
      "         0.6000,  0.8000,  1.0000])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(-1, 1, 11)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
